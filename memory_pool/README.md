# 内存池
## malloc
> new 和 delete 封装了operator new 和operator delete 而这两底层又在调用 malloc 和 free， 底层又是在调用brk() 和 mmap() 申请内存， 
1. brk()负责申请小块内存128K, 并且释放内存并不是返回操作系统，而是存放到小块内存池中 
2. mmap()会在堆区和栈区中间的文件直接映射区申请大块内存，这块区域释放才是直接向操作系统归还
3. malloc的实现有多种（内存池），windows下的vs和linux的gcc(ptmalloc)实现不同
---
## tcmalloc介绍

---
tcmalloc 在多线程环境下效率要高于glibc的malloc
> 此外还有jemalloc等


## 定长内存池实现

---
> .....


## tcmalloc框架



### thread cache

---
1. 使用TLS thread_local 为每一个线程使用独立的线程局部缓存内存池
2. 拥有208个自由链表分别对应 [1B~256KB] 字节的内存块，

> 在一定时机下归还从tc申请的内存块

- 每一个线程都会有其对应的tc.
- 每个线程去动态申请内存时不需要加锁，因为每个线程独享一个tc，如果tc中有空闲空间，线程在申请的时候只会去自己的tc中申请。
- 如果单次申请的空间是小于256KB的，线程就在自己的tc中申请，
- 单次申请的空间大于了256KB，则向cc申请内存

> 通过thread_local TLS 实现每个线程拥有自己的独立的内存分配器
> 每个线程内部拥有自己独立的208个freelist



### central cache

---
1. span: 由多个OS Page组成，提供一个自由链表指针，并且每个span会提供不同大小的内存块
2. span_list：每个span为一个节点，组成双向循环链表，该链表上的所有span提供的是相同大小的内存块
3. span_list[208] 哈希桶: 208个span循环链表数组，一一对应到thread_cache的208个不同大小内存块的自由链表你上
4. 每个链表都有自己的mutex，因此保证了只有不同的线程同时竞争同一个链表上的空间时才会竞争锁

> 在一定时机下归还从pc申请的span

- 当线程的tc空间用完后，会向cc申请空间。
- 当且仅当两个及以上的线程用完自己的tc后并发的访问cc去申请空间。
- cc内部由哈希桶实现，多个桶每个桶有一串空间，只有多个线程同时并发申请同一个桶的时候才会有线程安全问题，每一个桶自身会有一个桶锁。


> 内部维护一个span_list, 每一个span_list 负责提供不同内存块大小的span
> 

```text
cc中的span所有页都要映射到一个Span*上，因为cc中的span所管理的每一页都有用，
在tc归还小块空间时要通过对应page_id来找到对应span才能归还，
pc中的span内部的页则用不到，因为并没有分配出去，只会用到span两端的页号 用来合并。
```

### page cache

---
1. 同样拥有一个`spanlist[208]`： 但是按照内存页面数量不同来区分不同的`spalnlist`， 不同下标的spanlist中的span所包含的page是不同的
2. 

- 组织多个span结构体，span中会管理多个page，且会去标记这些span，当这几个page的内存都回来之后pc就会回收cc中满足条件的span。
- 一页是4KB或者8KB，回收回来的页，如果页号与其它页的页号可以拼成很多相邻页号，就会将这些相邻的页合并成更大的页，来解决内存碎片问题。

> pc释放出去的 k页的span 回收时也要尝试合并，而不是直接挂在响应page下的span_list中
> 否则当申请更大page的span时，小span过多无法得到利用，即产生大量外部碎片

```text
-问题- : 用use_count 来区分span是否可以用来合并 是不行的
cc获取到的span是由pc中拿来的，新的span正在由线程1进行小块切分的时候useCount是0
此时如果线程2正好去合并一些span，恰好看到了这个正在切分的span，useCount是0，直接拿过去合并，程序就出错了
-解决方法- : 为Span添加一个数据成员 bool， 区分该Span在cc中还是pc中
```

### TODO
> 替换哈希表为基数树
> 
> 添加读取环境变量设置默认不同的内存池
> 
> 添加读取配置文件设置内存池
> 
> 实现全局重载operator new 不死锁（目前内存池内部的哈希表也会调用operator new， 会导致死锁）
> 

---
  

